{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from datetime import datetime, timezone, timedelta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Project Directory\n",
    "PROJECT_DIR = '/workspace/Competition/map_segmentation'\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "# Data Directory\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data','final') # Folder containing train and test data\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train') # Folder containing train data\n",
    "TRAIN_IMG_DIR = os.path.join(TRAIN_DIR, 'images') # Folder containing train images\n",
    "TRAIN_MASK_DIR = os.path.join(TRAIN_DIR, 'masks') # Folder containing train masks\n",
    "TRAIN_CSV_FILE = os.path.join(TRAIN_DIR, 'traindf.csv') # Folder containing train key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Make unique serial number from current time\n",
    "kst = timezone(timedelta(hours=9))        \n",
    "train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Directory to save results\n",
    "RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)\n",
    "os.makedirs(RECORDER_DIR, exist_ok=True)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2022\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.003\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "IMG_SIZE = 512\n",
    "\n",
    "ENCODER = 'timm-efficientnet-b0' # Encoder model to be used\n",
    "WEIGHTS = 'imagenet' # Dataset used for pretraining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class SegDataset(Dataset):\n",
    "    def __init__(self, df, augmentations, img_dir, mask_dir):\n",
    "        self.df = df\n",
    "        self.augmentations = augmentations\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(self.img_dir,row['img'])\n",
    "        mask_path = os.path.join(self.mask_dir, row['mask'])\n",
    "        \n",
    "        # Load image and mask\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        \n",
    "        # Apply augmentations\n",
    "        if self.augmentations:\n",
    "            data = self.augmentations(image=image, mask=mask)\n",
    "            image = data['image']\n",
    "            mask = data['mask']\n",
    "        \n",
    "        # Reshape data\n",
    "        image = np.transpose(image, (2,0,1)).astype(np.float32)\n",
    "        mask = np.transpose(mask, (2,0,1)).astype(np.float32)\n",
    "        \n",
    "        # Image normalization\n",
    "        image = torch.Tensor(image) / 255.0\n",
    "        mask = torch.round(torch.Tensor(mask)/255.0)\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class SegModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegModel, self).__init__()\n",
    "        \n",
    "        self.backbone = smp.Unet(\n",
    "            encoder_name = ENCODER,\n",
    "            encoder_weights = WEIGHTS,\n",
    "            in_channels = 3, \n",
    "            classes = 1,\n",
    "            activation = None\n",
    "        )\n",
    "        \n",
    "    def forward(self, images):\n",
    "        logits = self.backbone(images)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_augs():\n",
    "    return A.Compose([\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5)\n",
    "    ])\n",
    "\n",
    "def get_valid_augs():\n",
    "    return A.Compose([\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE)\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(dataloader, model, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for images,masks in tqdm(dataloader):\n",
    "        images = images.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = loss_fn(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss/len(dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def valid_fn(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images,masks in tqdm(dataloader):\n",
    "            images = images.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "            logits = model(images)\n",
    "            loss = loss_fn(logits, masks)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss/len(dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Train data key\n",
    "entiredf = pd.read_csv(TRAIN_CSV_FILE)\n",
    "\n",
    "# Split data into train and validation datasets\n",
    "traindf, validdf = train_test_split(entiredf, test_size=0.2)\n",
    "traindf = traindf.reset_index(drop=True)\n",
    "validdf = validdf.reset_index(drop=True)\n",
    "\n",
    "# Make datasets and dataloaders\n",
    "train_dataset = SegDataset(traindf, get_train_augs(), TRAIN_IMG_DIR, TRAIN_MASK_DIR)\n",
    "valid_dataset = SegDataset(validdf, get_valid_augs(), TRAIN_IMG_DIR, TRAIN_MASK_DIR)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model, loss function, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model = SegModel().to(DEVICE) \n",
    "loss_fn = DiceLoss(mode = 'binary') \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 842/842 [04:32<00:00,  3.09it/s]\n",
      "100%|██████████| 211/211 [00:35<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n",
      "Epoch: 1, Train Loss: 0.24479317643863288 Valid Loss: 0.1882980796398145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 842/842 [04:33<00:00,  3.08it/s]\n",
      "100%|██████████| 211/211 [00:35<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n",
      "Epoch: 2, Train Loss: 0.18856132915354115 Valid Loss: 0.16962257465480063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.Inf\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    train_loss = train_fn(train_loader, model, optimizer, loss_fn)\n",
    "    valid_loss = valid_fn(valid_loader, model, loss_fn)\n",
    "    \n",
    "    # Save model if loss decreases\n",
    "    if valid_loss < best_loss:\n",
    "        torch.save(model.state_dict(), os.path.join(RECORDER_DIR, \"best-model.pt\"))\n",
    "        print('saved model')\n",
    "        best_loss = valid_loss\n",
    "        print(f\"Epoch: {i+1}, Train Loss: {train_loss} Valid Loss: {valid_loss}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to convert Mask to RLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def mask_to_rle(mask):\n",
    "    flatten_mask = mask.flatten()\n",
    "    if flatten_mask.max() == 0:\n",
    "        return f'0 {len(flatten_mask)}'\n",
    "    idx = np.where(flatten_mask!=0)[0]\n",
    "    steps = idx[1:]-idx[:-1]\n",
    "    new_coord = []\n",
    "    step_idx = np.where(np.array(steps)!=1)[0]\n",
    "    start = np.append(idx[0], idx[step_idx+1])\n",
    "    end = np.append(idx[step_idx], idx[-1])\n",
    "    length = end - start + 1\n",
    "    for i in range(len(start)):\n",
    "        new_coord.append(start[i])\n",
    "        new_coord.append(length[i])\n",
    "    new_coord_str = ' '.join(map(str, new_coord))\n",
    "    return new_coord_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, img_dir):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        imname = row['img']\n",
    "        image_path = os.path.join(self.img_dir,imname)\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = np.transpose(image, (2,0,1)).astype(np.float32)\n",
    "        image = torch.Tensor(image) / 255.0\n",
    "        \n",
    "        return image,imname"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "TEST_DIR = os.path.join(DATA_DIR, 'test') \n",
    "TEST_IMG_DIR = os.path.join(TEST_DIR, 'images') \n",
    "TEST_CSV_FILE = os.path.join(TEST_DIR, 'testdf.csv')\n",
    "\n",
    "testdf = pd.read_csv(TEST_CSV_FILE)\n",
    "test_dataset = TestDataset(testdf, TEST_IMG_DIR)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1,shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(RECORDER_DIR, 'best-model.pt')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2120it [01:17, 27.42it/s]\n"
     ]
    }
   ],
   "source": [
    "file_list = [] \n",
    "pred_list = [] \n",
    "class_list = [] \n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (image,imname) in tqdm(enumerate(test_loader)):\n",
    "        image = image.to(DEVICE)\n",
    "        logit_mask = model(image)\n",
    "        pred_mask = torch.sigmoid(logit_mask) \n",
    "        pred_mask = (pred_mask > 0.5) * 1.0 \n",
    "        pred_rle = mask_to_rle(pred_mask.detach().cpu().squeeze(0))\n",
    "        pred_list.append(pred_rle)\n",
    "        file_list.append(imname[0])\n",
    "        class_list.append(\"building\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions in format of sample submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspace/Competition/map_segmentation/data/final/test/sample_submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/Competition/map_segmentation/baseline.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmapseg/workspace/Competition/map_segmentation/baseline.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mimg_id\u001b[39m\u001b[39m'\u001b[39m:file_list,\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m:class_list,\u001b[39m'\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m'\u001b[39m:pred_list})\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmapseg/workspace/Competition/map_segmentation/baseline.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Change order of predictions to match that of sample_submission\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmapseg/workspace/Competition/map_segmentation/baseline.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m sampledf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(TEST_DIR, \u001b[39m'\u001b[39;49m\u001b[39msample_submission.csv\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmapseg/workspace/Competition/map_segmentation/baseline.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m sorter \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(sampledf[\u001b[39m'\u001b[39m\u001b[39mimg_id\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmapseg/workspace/Competition/map_segmentation/baseline.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m results \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mimg_id\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1219\u001b[0m     f,\n\u001b[1;32m   1220\u001b[0m     mode,\n\u001b[1;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1227\u001b[0m )\n\u001b[1;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/workspace/Competition/map_segmentation/data/final/test/sample_submission.csv'"
     ]
    }
   ],
   "source": [
    "# Make dataframe of predictions\n",
    "results = pd.DataFrame({'img_id':file_list,'class':class_list,'prediction':pred_list})\n",
    "\n",
    "# Change order of predictions to match that of sample_submission\n",
    "sampledf = pd.read_csv(os.path.join(TEST_DIR, 'sample_submission.csv'))\n",
    "sorter = list(sampledf['img_id'])\n",
    "results = results.set_index('img_id')\n",
    "results = results.loc[sorter].reset_index()\n",
    "                       \n",
    "# Save predictions\n",
    "results.to_csv(os.path.join(RECORDER_DIR, 'prediction.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
