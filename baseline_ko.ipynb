{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모의경진대회] 토지피복지도 객체분할"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필수 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from datetime import datetime, timezone, timedelta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIG 설정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# 프로젝트 경로\n",
    "PROJECT_DIR = '/workspace/Competition/map_segmentation'\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "#데이터 경로\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data','final') # 모든 데이터가 들어있는 폴더 경로\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train') # 학습 데이터가 들어있는 폴더 경로\n",
    "TRAIN_IMG_DIR = os.path.join(TRAIN_DIR, 'images') # 학습 이미지가 들어있는 폴더 경로\n",
    "TRAIN_MASK_DIR = os.path.join(TRAIN_DIR, 'masks') # 학습 마스크가 들어있는 폴더 경로\n",
    "TRAIN_CSV_FILE = os.path.join(TRAIN_DIR, 'traindf.csv') # 학습 이미지와 마스크 이름이 들어있는 CSV 경로"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 저장 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# 시간 고유값 \n",
    "kst = timezone(timedelta(hours=9))        \n",
    "train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 기록 경로\n",
    "RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)\n",
    "# 현재 시간 기준 폴더 생성\n",
    "os.makedirs(RECORDER_DIR, exist_ok=True)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2022 #랜덤 시드\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디바이스 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.003\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "IMG_SIZE = 512\n",
    "\n",
    "ENCODER = 'timm-efficientnet-b0' # 활용할 인코더 모델\n",
    "WEIGHTS = 'imagenet' # Pre-train에 활용된 데이터셋"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class SegDataset(Dataset):\n",
    "    def __init__(self, df, augmentations, img_dir, mask_dir):\n",
    "        self.df = df # 이미지와 마스크 이름이 저장된 데이터프레임 \n",
    "        self.augmentations = augmentations # 학습 전 적용할 augmentation\n",
    "        self.img_dir = img_dir # 이미지 폴더 경로\n",
    "        self.mask_dir = mask_dir # 마스크 폴더 경로\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 데이터 프레임 불러와서 이미지와 마스크 경로 설정\n",
    "        row = self.df.iloc[idx] # 데이터프레임 행 불러오기\n",
    "        image_path = os.path.join(self.img_dir,row['img'])\n",
    "        mask_path = os.path.join(self.mask_dir, row['mask'])\n",
    "        \n",
    "        # 이미지와 마스크 불러오기\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        \n",
    "        # Augmentation 적용하기\n",
    "        if self.augmentations:\n",
    "            data = self.augmentations(image=image, mask=mask)\n",
    "            image = data['image']\n",
    "            mask = data['mask']\n",
    "        \n",
    "        # PyTorch 인풋 모양에 맞게 이미지와 마스크 모양 변경\n",
    "        image = np.transpose(image, (2,0,1)).astype(np.float32)\n",
    "        mask = np.transpose(mask, (2,0,1)).astype(np.float32)\n",
    "        \n",
    "        # 이미지 Normalization 0~255 픽셀값 --> 0~1 픽셀값\n",
    "        image = torch.Tensor(image) / 255.0\n",
    "        mask = torch.round(torch.Tensor(mask)/255.0)\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class SegModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegModel, self).__init__()\n",
    "        \n",
    "        # Pre-train된 UNET 불러오기\n",
    "        self.backbone = smp.Unet(\n",
    "            encoder_name = ENCODER, # 인코더 모델 설정\n",
    "            encoder_weights = WEIGHTS, # 사전학습 데이터셋 설정\n",
    "            in_channels = 3, # 이미지 디멘션 (3 * 512 * 512)\n",
    "            classes = 1, # 세그멘테이션 클래스 개수 \n",
    "            activation = None # logit 값 불러오기\n",
    "        )\n",
    "        \n",
    "    def forward(self, images):\n",
    "        logits = self.backbone(images)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils 정의"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_augs():\n",
    "    return A.Compose([\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE), # 이미지 크기 변환\n",
    "        A.HorizontalFlip(p=0.5), # 이미지 좌우반전\n",
    "        A.VerticalFlip(p=0.5) # 이미지 상하반전\n",
    "    ])\n",
    "\n",
    "def get_valid_augs():\n",
    "    return A.Compose([\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE)\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(dataloader, model, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for images,masks in tqdm(dataloader):\n",
    "        images = images.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = loss_fn(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss/len(dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def valid_fn(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images,masks in tqdm(dataloader):\n",
    "            images = images.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "            logits = model(images)\n",
    "            loss = loss_fn(logits, masks)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss/len(dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset & Dataloader 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# 학습 이미지, 마스크 이름 들어있는 CSV 불러와 데이터 프레임으로 저장\n",
    "entiredf = pd.read_csv(TRAIN_CSV_FILE)\n",
    "\n",
    "# Train과 Validation 데이터셋으로 나누기\n",
    "traindf, validdf = train_test_split(entiredf, test_size=0.2)\n",
    "traindf = traindf.reset_index(drop=True)\n",
    "validdf = validdf.reset_index(drop=True)\n",
    "\n",
    "# Dataset 및 Dataloader 설정\n",
    "train_dataset = SegDataset(traindf, get_train_augs(), TRAIN_IMG_DIR, TRAIN_MASK_DIR)\n",
    "valid_dataset = SegDataset(validdf, get_valid_augs(), TRAIN_IMG_DIR, TRAIN_MASK_DIR)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델, Loss, Optimizer 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model = SegModel().to(DEVICE) # 모델 설정\n",
    "loss_fn = DiceLoss(mode = 'binary') # 학습 loss funciton 설정\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) # optimizer 설정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 단위 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 842/842 [04:32<00:00,  3.09it/s]\n",
      "100%|██████████| 211/211 [00:34<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n",
      "Epoch: 1, Train Loss: 0.24479317643863288 Valid Loss: 0.1882980796398145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 842/842 [04:31<00:00,  3.11it/s]\n",
      "100%|██████████| 211/211 [00:34<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n",
      "Epoch: 2, Train Loss: 0.18856132915354115 Valid Loss: 0.16962257465480063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 842/842 [04:32<00:00,  3.09it/s]\n",
      "100%|██████████| 211/211 [00:34<00:00,  6.12it/s]\n",
      "100%|██████████| 842/842 [04:30<00:00,  3.11it/s]\n",
      "100%|██████████| 211/211 [00:33<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n",
      "Epoch: 4, Train Loss: 0.16546692184201328 Valid Loss: 0.16082554292904822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 842/842 [04:30<00:00,  3.11it/s]\n",
      "100%|██████████| 211/211 [00:34<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n",
      "Epoch: 5, Train Loss: 0.16125684176657942 Valid Loss: 0.15086359576591382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 842/842 [04:31<00:00,  3.10it/s]\n",
      "100%|██████████| 211/211 [00:34<00:00,  6.10it/s]\n",
      "100%|██████████| 842/842 [04:32<00:00,  3.09it/s]\n",
      "100%|██████████| 211/211 [00:34<00:00,  6.12it/s]\n",
      "100%|██████████| 842/842 [04:30<00:00,  3.11it/s]\n",
      "100%|██████████| 211/211 [00:35<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n",
      "Epoch: 8, Train Loss: 0.1540904399051802 Valid Loss: 0.13840618037499522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 842/842 [04:31<00:00,  3.11it/s]\n",
      "100%|██████████| 211/211 [00:34<00:00,  6.13it/s]\n",
      "100%|██████████| 842/842 [04:30<00:00,  3.11it/s]\n",
      "100%|██████████| 211/211 [00:33<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n",
      "Epoch: 10, Train Loss: 0.14830893936463035 Valid Loss: 0.13805741128198343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.Inf\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    train_loss = train_fn(train_loader, model, optimizer, loss_fn)\n",
    "    valid_loss = valid_fn(valid_loader, model, loss_fn)\n",
    "    \n",
    "    # loss가 감소하면 모델 저장\n",
    "    if valid_loss < best_loss:\n",
    "        torch.save(model.state_dict(), os.path.join(RECORDER_DIR, \"best-model.pt\"))\n",
    "        print('saved model')\n",
    "        best_loss = valid_loss\n",
    "        print(f\"Epoch: {i+1}, Train Loss: {train_loss} Valid Loss: {valid_loss}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마스크를 RLE형태로 변환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def mask_to_rle(mask):\n",
    "    flatten_mask = mask.flatten()\n",
    "    if flatten_mask.max() == 0:\n",
    "        return f'0 {len(flatten_mask)}'\n",
    "    idx = np.where(flatten_mask!=0)[0]\n",
    "    steps = idx[1:]-idx[:-1]\n",
    "    new_coord = []\n",
    "    step_idx = np.where(np.array(steps)!=1)[0]\n",
    "    start = np.append(idx[0], idx[step_idx+1])\n",
    "    end = np.append(idx[step_idx], idx[-1])\n",
    "    length = end - start + 1\n",
    "    for i in range(len(start)):\n",
    "        new_coord.append(start[i])\n",
    "        new_coord.append(length[i])\n",
    "    new_coord_str = ' '.join(map(str, new_coord))\n",
    "    return new_coord_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspace/Competition/map_segmentation/baseline.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmapseg/workspace/Competition/map_segmentation/baseline.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mTestDataset\u001b[39;00m(Dataset):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmapseg/workspace/Competition/map_segmentation/baseline.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, df, img_dir):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmapseg/workspace/Competition/map_segmentation/baseline.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, img_dir):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        imname = row['img']\n",
    "        image_path = os.path.join(self.img_dir,imname)\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = np.transpose(image, (2,0,1)).astype(np.float32)\n",
    "        image = torch.Tensor(image) / 255.0\n",
    "        \n",
    "        return image,imname"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경로 설정 및 Test 데이터 부러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "TEST_DIR = os.path.join(DATA_DIR, 'test') # 테스트 데이터가 들어있는 폴더 경로\n",
    "TEST_IMG_DIR = os.path.join(TEST_DIR, 'images') # 테스트 이미지가 들어있는 폴더 경로\n",
    "TEST_CSV_FILE = os.path.join(TEST_DIR, 'testdf.csv') # 테스트 이미지 이름이 들어있는 CSV 경로\n",
    "testdf = pd.read_csv(TEST_CSV_FILE)\n",
    "test_dataset = TestDataset(testdf, TEST_IMG_DIR)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1,shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최고 성능 모델 가중치 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(RECORDER_DIR, 'best-model.pt')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "file_list = [] # 이미지 이름 저장할 리스트\n",
    "pred_list = [] # 마스크 저장할 리스트\n",
    "class_list = [] # 클래스 이름 저장할 리스트 ('building')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (image,imname) in tqdm(enumerate(test_loader)):\n",
    "        image = image.to(DEVICE)\n",
    "        logit_mask = model(image)\n",
    "        pred_mask = torch.sigmoid(logit_mask) # logit 값을 probability score로 변경\n",
    "        pred_mask = (pred_mask > 0.5) * 1.0 # 0.5 이상 확률 가진 픽셀값 1로 변환\n",
    "        pred_rle = mask_to_rle(pred_mask.detach().cpu().squeeze(0)) # 마스크를 RLE 형태로 변경\n",
    "        pred_list.append(pred_rle)\n",
    "        file_list.append(imname[0])\n",
    "        class_list.append(\"building\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 결과 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# 예측 결과 데이터프레임 만들기\n",
    "results = pd.DataFrame({'img_id':file_list,'class':class_list,'prediction':pred_list})\n",
    "\n",
    "# sample_submission.csv와 같은 형태로 변형\n",
    "sampledf = pd.read_csv(os.path.join(TEST_DIR, 'sample_submission.csv'))\n",
    "sorter = list(sampledf['img_id'])\n",
    "results = results.set_index('img_id')\n",
    "results = results.loc[sorter].reset_index()\n",
    "                       \n",
    "# 결과 저장\n",
    "results.to_csv(os.path.join(RECORDER_DIR, 'prediction.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
